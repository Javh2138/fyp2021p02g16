{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IT University of Copenhagen\n",
    "## First year project - Project 2\n",
    "### Investigating weather data and corona data in the Netherlands\n",
    "#### Jacob Victor Enggaard Haahr, \n",
    "#### Christian Hugo Rasmussen \n",
    "#### Victoria Gonzalez\n",
    "#### Lukas Rasocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the neccessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import json\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and filtering data\n",
    "\n",
    "nl_covid = pd.read_csv('../data/Raw/corona/nl_corona.csv',sep='\\t')\n",
    "tests = pd.read_csv('../data/Raw/external/covid-19_tests.csv',sep=';')\n",
    "weather = pd.read_csv('../data/Raw/weather/weather.csv',sep='\\t')\n",
    "with open('../data/Raw/metadata/nl_metadata.json') as f:\n",
    "    metadata = json.load(f)\n",
    "nl_weather = weather['iso3166-2'].str[:2] == 'NL'\n",
    "nl_weather_df = weather[nl_weather]\n",
    "\n",
    "reg_dict = {}\n",
    "names = {}\n",
    "for i in metadata['country_metadata']:\n",
    "    reg_dict[int(i['covid_region_code'])] = [i['population']]\n",
    "    names[int(i['covid_region_code'])] = i['iso3166-2_code']\n",
    "    \n",
    "\n",
    "reg_names = set(nl_covid['region_code'])\n",
    "mask1 = nl_covid['confirmed_addition'].dropna()\n",
    "mask_idk = nl_covid['confirmed_addition'].notnull()\n",
    "\n",
    "\n",
    "for i in list(reg_names):\n",
    "    mask = (nl_covid['region_code'] == i) & (nl_covid['confirmed_addition'].notnull())\n",
    "    mask_covid=nl_covid[mask]\n",
    "    reg_dict[i].append(sum(mask_covid['confirmed_addition']))\n",
    "df1 = pd.DataFrame.from_dict(reg_dict)\n",
    "df1 = df1.transpose()\n",
    "final_df = df1.rename(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have found an external dataset that used smaller subregions of the netherlands, we therefore renamed them to be included\n",
    "#in the bigger regions that are defined by the gejson file\n",
    "\n",
    "#making a list of all regionnames in tests which should be replaced\n",
    "#with the nl_covid regions\n",
    "gelder = [\"Gelderland-Midden\",\"Gelderland-Zuid\",\"Noord- en Oost-Gelderland\"]\n",
    "over = [\"IJsselland\", \"Twente\"]\n",
    "#flev = [\"Flevoland\"]\n",
    "#Gron = [\"Groningen\"]\n",
    "#Zee = [\"Zeeland\"]\n",
    "Zhol = [\"Haaglanden\",\"Hollands-Midden\",\"Rotterdam-Rijnmond\",\"Zuid-Holland-Zuid\"]\n",
    "Nhol = [\"Gooi en Vechtstreek\", \"Kennemerland\", \"Noord-Holland-Noord\",\"Zaanstreek-Waterland\",\"Amsterdam-Amstelland\"]\n",
    "#Utrecht = [\"Utrecht\"]\n",
    "Lim = [\"Limburg-Noord\",\"Limburg-Zuid\"]\n",
    "Nbra = [\"Brabant-Noord\",\"Brabant-Zuidoost\",\"Midden- en West-Brabant\"]\n",
    "Frie = [\"FryslÃ¢n\"]\n",
    "#Dren = [\"Drenthe\"]\n",
    "#Remove Onbekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the regionnames with matching regions based on our data\n",
    "tests[\"Security_region_name\"].replace(gelder,\"Gelderland\", inplace=True)\n",
    "tests[\"Security_region_name\"].replace(over,\"Overijssel\", inplace=True)\n",
    "tests[\"Security_region_name\"].replace(Zhol,\"Zuid-Holland\", inplace=True)\n",
    "tests[\"Security_region_name\"].replace(Nhol,\"Noord-Holland\", inplace=True)\n",
    "tests[\"Security_region_name\"].replace(Lim,\"Limburg\", inplace=True)\n",
    "tests[\"Security_region_name\"].replace(Nbra,\"Noord-Brabant\", inplace=True)\n",
    "tests[\"Security_region_name\"].replace(Frie,\"Friesland\", inplace=True)\n",
    "\n",
    "onbekendt_mask = (tests['Security_region_name'] != \"Onbekend\")\n",
    "\n",
    "#removing unknown variable with data without a region\n",
    "tests = tests[onbekendt_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the date from a string to a datetime class\n",
    "tests['Date_of_statistics'] = pd.to_datetime(tests[\"Date_of_statistics\"],format= \"%d/%m/%Y\")\n",
    "#creating new column in the data frame for weekends\n",
    "tests['weekend'] = (pd.to_datetime(tests['Date_of_statistics'],format = '%Y-%m-%d').dt.weekday >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Finding min, median, max and mean for each numerical value, for each region in the Netherlands.'''\n",
    "\n",
    "num_columns = ['RelativeHumiditySurface','SolarRadiation','Surfacepressure','TemperatureAboveGround','Totalprecipitation','UVIndex','WindSpeed']\n",
    "reg_dict = {}\n",
    "for i in nl_weather_df['iso3166-2'].unique():\n",
    "    reg_dict[i] = {}\n",
    "    for j in num_columns:\n",
    "        reg_dict[i][j] = {'min': min(nl_weather_df[nl_weather_df['iso3166-2'] == i][j]),'median':np.median(nl_weather_df[nl_weather_df['iso3166-2'] == i][j]),'max':max(nl_weather_df[nl_weather_df['iso3166-2'] == i][j]),'mean':np.mean(nl_weather_df[nl_weather_df['iso3166-2'] == i][j])}\n",
    "#reg_dict['NL-GE']['RelativeHumiditySurface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Calculate the mean per every date for all the numerical columns\n",
    "date_dict = {}\n",
    "for i in nl_weather_df['date'].unique():\n",
    "    date_dict[i] = {}\n",
    "    for j in num_columns:\n",
    "        date_dict[i][j] = np.mean(nl_weather_df[nl_weather_df['date'] == i][j])\n",
    "#date_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting means of UVindices for different regions\n",
    "means = [reg_dict[i]['UVIndex']['mean'] for i in reg_dict.keys()]\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(reg_dict.keys(),means);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_by_day_nl = nl_weather_df.groupby(by = \"date\").mean()\n",
    "\n",
    "weather_by_day_nl.loc[:, \"UVIndex\"].plot.line().legend(loc = \"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the coordinates for different regions to plot them using folium\n",
    "nl_map = folium.Map(location = [52.3,5.5], zoom_start = 7.4)\n",
    "folium.GeoJson('../Data/Raw/shapefiles/nl.geojson', name = \"geojson\").add_to(nl_map)\n",
    "folium.LayerControl().add_to(nl_map)\n",
    "\n",
    "nl_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming dataframe's columns\n",
    "final_df.columns = ['population', 'cases']\n",
    "df = final_df.reset_index()\n",
    "df.columns = [\"region\",'population', 'cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column in our data frame with the cases per capita\n",
    "df[\"cases_pc\"] = df[\"cases\"] / df[\"population\"]*100\n",
    "\n",
    "\n",
    "nl_map = folium.Map(location = [52.3,5.5], zoom_start = 7.4)\n",
    "folium.Choropleth(\n",
    "    geo_data = '../Data/Raw/shapefiles/nl.geojson',\n",
    "    name = \"cases\",\n",
    "    data = df,\n",
    "    columns = ['region', 'cases_pc'],\n",
    "    key_on = \"properties.iso_3166_2\",\n",
    "    fill_color = \"OrRd\",\n",
    "    fill_opacity = 0.7,\n",
    "    line_opacity = 0.2,\n",
    "    legend_name = \"number of cases %\",\n",
    ").add_to(nl_map)\n",
    "\n",
    "nl_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning covid data set by dropping columns that we didn't use and replacing names so we can merge it on that later on\n",
    "mask = nl_covid['confirmed_addition'].notnull()\n",
    "nl_covid_clean = nl_covid[mask]\n",
    "nl_covid_clean = nl_covid_clean.drop(['deceased_addition','hospitalized_addition','deceased_cumulative','confirmed_cumulative','hospitalized_cumulative'], axis=1)\n",
    "region_codes = set(nl_covid_clean['region_code'])\n",
    "\n",
    "nl_covid_clean['region_code'].replace(list(names.keys()), list(names.values()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge weather data with covid data\n",
    "weather_corona = nl_covid_clean.merge(nl_weather_df, left_on=['date','region_code'],right_on=['date','iso3166-2'])\n",
    "weather_corona.drop(['region_code'],axis=1) #remove duplicate column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing correlations for numerical variables in combined weather and covid dataframe - spearman, pearson, log\n",
    "\n",
    "withoutzeros = weather_corona[\"confirmed_addition\"].clip(lower=1) #enabling us to do log by changin 0's to 1's\n",
    "sig_thresh = 0.001 / len(num_columns)*3\n",
    "\n",
    "for var in num_columns:\n",
    "    corr,p = pearsonr(weather_corona['confirmed_addition'],weather_corona[var])\n",
    "    corr2,p2 = spearmanr(weather_corona['confirmed_addition'],weather_corona[var])\n",
    "    corr3,p3 = pearsonr(np.log(withoutzeros),weather_corona[var])\n",
    "    print('------------ '+var+' --------------')\n",
    "    print(\"-----Pearson------\")\n",
    "    print(\"Correlation\",corr)\n",
    "    print(\"P value\",p,p<sig_thresh)\n",
    "    print(\"-----Spearman------\")\n",
    "    print(\"Correlation\", corr2)\n",
    "    print(\"P value\", p2,p<sig_thresh)\n",
    "    print(\"------LOG-------\")\n",
    "    print(\"Correlation\", corr3)\n",
    "    print(\"P value\", p3,p<sig_thresh)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe containing only cases during spring lockdown\n",
    "lockdown = (nl_covid['date'] > '2020-03-15') & (nl_covid['date'] < '2020-04-28')\n",
    "\n",
    "yes = nl_covid[lockdown]\n",
    "nl_covid_by_day =  yes.groupby(by='date').mean()\n",
    "nl_covid_by_day.loc[:,'confirmed_addition'].plot.line(rot=90).legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting covid and weather data by weeks, to better visualize data\n",
    "plt.figure(0)\n",
    "weather_corona['date'] = pd.to_datetime(weather_corona['date']) - pd.to_timedelta(7, unit='d')\n",
    "df = weather_corona.groupby(['region_name', pd.Grouper(key='date', freq='W-MON')])['RelativeHumiditySurface'].sum().reset_index().sort_values('date')\n",
    "df['RelativeHumiditySurface'] = df['RelativeHumiditySurface']/7\n",
    "nl_covid_by_day =  df.groupby(by='date').mean()\n",
    "nl_covid_by_day.loc[:,'RelativeHumiditySurface'].plot.line(rot=90).legend(loc='upper left')\n",
    "plt.figure(1)\n",
    "nl_covid['date'] = pd.to_datetime(nl_covid['date']) - pd.to_timedelta(7, unit='d')\n",
    "df = nl_covid.groupby(['region_name', pd.Grouper(key='date', freq='W-MON')])['confirmed_addition'].sum().reset_index().sort_values('date')\n",
    "df['confirmed_addition'] = df['confirmed_addition']/7\n",
    "nl_covid_by_day =  df.groupby(by='date').mean()\n",
    "nl_covid_by_day.loc[:,'confirmed_addition'].plot.line(rot=90).legend(loc='upper left')\n",
    "plt.figure(2)\n",
    "weather_corona['date'] = pd.to_datetime(weather_corona['date']) - pd.to_timedelta(7, unit='d')\n",
    "df = weather_corona.groupby(['region_name', pd.Grouper(key='date', freq='W-MON')])['UVIndex'].sum().reset_index().sort_values('date')\n",
    "df['UVIndex'] = df['UVIndex']/7\n",
    "nl_covid_by_day =  df.groupby(by='date').mean()\n",
    "nl_covid_by_day.loc[:,'UVIndex'].plot.line(rot=90).legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Timeline of daily covid confirmed cases\n",
    "#Colouring lines based on different events during the 2020 and partially 2021\n",
    "\n",
    "first_lockdown = (nl_covid['date'] > '2020-03-15') & (nl_covid['date'] < '2020-04-28')\n",
    "october_partial_lockdown = (nl_covid['date'] > '2020-10-14') & (nl_covid['date'] <= '2020-12-15')\n",
    "hard_december_lockdown = (nl_covid['date'] > '2020-12-15') & (nl_covid['date'] < '2021-03-15')\n",
    "plt.figure(figsize=(15,10))\n",
    "nl_covid_by_day =  nl_covid.groupby(by='date').mean()\n",
    "first_lockdown_by_day = nl_covid[first_lockdown].groupby('date').mean()\n",
    "october_partial_lockdown_by_day  = nl_covid[october_partial_lockdown].groupby('date').mean()\n",
    "hard_december_lockdown_by_day  = nl_covid[hard_december_lockdown].groupby('date').mean()\n",
    "\n",
    "ax = nl_covid_by_day.loc[:,'confirmed_addition'].plot.line(color='k',rot=90,label='Confirmed addition') #covid addition daily\n",
    "first_lockdown_by_day.loc[:,'confirmed_addition'].plot.line(color ='r',label='First lockdown',ax=ax) #first lockdown\n",
    "october_partial_lockdown_by_day.loc[:,'confirmed_addition'].plot.line(color ='purple',label='Partial lockdown',ax=ax) #october partial lockdown\n",
    "hard_december_lockdown_by_day.loc[:,'confirmed_addition'].plot.line(color ='darkgreen',label='Full lockdown',ax=ax) #october partial lockdown\n",
    "plt.axvline('2020-12-19',label='Mutant strain ',color='slateblue')\n",
    "plt.axvline('2021-01-09',label='Vaccination ',color='lawngreen')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the average UVIndex per region\n",
    "region_UVindex = {}\n",
    "\n",
    "reg_names = set(weather_corona['region_code'])\n",
    "\n",
    "for name in list(reg_names):\n",
    "    mask = weather_corona['region_code'] == name\n",
    "    region_UVindex[name] = [sum(weather_corona[mask]['UVIndex'])/len(weather_corona[mask])]\n",
    "\n",
    "region_humidity_df = pd.DataFrame.from_dict(region_UVindex)\n",
    "region_humidity_df = region_humidity_df.transpose().reset_index()\n",
    "region_humidity_df.rename(columns = {'index':'region',0:'AVG UV'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average UVIndex by region\n",
    "nl_map = folium.Map(location = [52.3,5.5], zoom_start = 7.4)\n",
    "folium.Choropleth(\n",
    "    geo_data = '../Data/Raw/shapefiles/nl.geojson',\n",
    "    name = \"AVG UV\",\n",
    "    data = region_humidity_df,\n",
    "    columns = ['region', 'AVG UV'],\n",
    "    key_on = \"properties.iso_3166_2\",\n",
    "    fill_color = \"OrRd\",\n",
    "    fill_opacity = 0.7,\n",
    "    line_opacity = 0.2,\n",
    "    legend_name = \"average UV\",\n",
    ").add_to(nl_map)\n",
    "\n",
    "nl_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy variables for lockdown, holidays and weekends to see if any of them is correlated to the number of cases\n",
    "Lockdown_True = (weather_corona['date'] > '2020-03-15') & (weather_corona['date'] < '2020-04-28') | (weather_corona['date'] > '2020-10-14') & (weather_corona['date'] <= '2020-12-15') | (weather_corona['date'] > '2020-12-15') & (weather_corona['date'] < '2021-03-15')\n",
    "weather_corona['Lockdown'] = list(Lockdown_True)\n",
    "weather_corona['Lockdown'].replace([True,False],[1,0],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns.append('holiday')\n",
    "num_columns.append('Lockdown')\n",
    "num_columns.append('weekend')\n",
    "num_columns.append('no_school')\n",
    "weather_corona['weekend'] = 0\n",
    "weather_corona['weekend'] = (pd.to_datetime(weather_corona['date'],format = '%Y-%m-%d').dt.weekday >= 5).astype(int)\n",
    "weather_corona['holiday'] = 0\n",
    "\n",
    "no_school = (weather_corona['date'] > '2020-03-12') & (weather_corona['date']<'2020-06-08')\n",
    "weather_corona['no_school'] = list(no_school)\n",
    "weather_corona['no_school'].replace([True,False],[1,0],inplace=True)\n",
    "weather_corona.loc[weather_corona['date'] == '2020-01-01','holiday'] = 1\n",
    "weather_corona.loc[weather_corona['date'] == '2020-04-10','holiday'] = 1\n",
    "weather_corona.loc[weather_corona['date'] == '2020-04-12','holiday'] = 1\n",
    "weather_corona.loc[weather_corona['date'] == '2020-04-13','holiday'] = 1\n",
    "weather_corona.loc[weather_corona['date'] == '2020-04-27','holiday'] = 1\n",
    "weather_corona.loc[weather_corona['date'] == '2020-05-05','holiday'] = 1\n",
    "weather_corona.loc[weather_corona['date'] == '2020-05-21','holiday'] = 1\n",
    "weather_corona.loc[weather_corona['date'] == '2020-05-31','holiday'] = 1\n",
    "weather_corona.loc[weather_corona['date'] == '2020-06-01','holiday'] = 1\n",
    "weather_corona.loc[weather_corona['date'] == '2020-12-25','holiday'] = 1\n",
    "weather_corona.loc[weather_corona['date'] == '2020-12-26','holiday'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging 2 dataframes to get the total number of cases and population in each of the regions, to be able to calculate cases per capita\n",
    "df = final_df.reset_index()\n",
    "df.columns = [\"region\",'population', 'cases']\n",
    "weather_corona = weather_corona.merge(df, left_on=['region_code'],right_on=['region'])\n",
    "weather_corona.drop('region',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multivariable analysis\n",
    "weather_corona = sm.add_constant(weather_corona)\n",
    "num_columns.append('const')\n",
    "weather_corona['cases_per_c'] = weather_corona['confirmed_addition']/weather_corona['population']\n",
    "est = sm.OLS(weather_corona['cases_per_c'],weather_corona[num_columns], hasconst = True).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multivariable analysis with our external dataset\n",
    "tests['const'] = 1\n",
    "\n",
    "est = sm.OLS(tests['Tested_positive'],tests[['Tested_with_result','weekend','const']], hasconst = True).fit()\n",
    "print(est.summary())\n",
    "\n",
    "sig_thresh = 0.000001 / 2\n",
    "\n",
    "corr,p = pearsonr(tests['Tested_positive'],tests['Tested_with_result'])\n",
    "corr2,p2 = spearmanr(tests['Tested_positive'],tests['Tested_with_result'])\n",
    "\n",
    "\n",
    "print(\"-----Pearson------\")\n",
    "print(\"Correlation\",corr)\n",
    "print(\"P value\",p,p<sig_thresh)\n",
    "print(\"-----Spearman------\")\n",
    "print(\"Correlation\", corr2)\n",
    "print(\"P value\", p2,p<sig_thresh)\n",
    "print(\"------LOG-------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the relationship between UV index and confirmed additions, trying to see if they are correlated\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "axes = fig.add_axes([0,0,1,1])\n",
    "axes.set_xlabel('Uv Index')\n",
    "axes.set_ylabel('Confirmed addition')\n",
    "axes.scatter(weather_corona['UVIndex'], weather_corona['confirmed_addition'],edgecolor='k',color='lawngreen');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the data type of our dates in the external dataset\n",
    "tests[\"Date_of_statistics\"] = pd.to_datetime(tests[\"Date_of_statistics\"],format= \"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed to map the Region names (Drenthe etc.) to codes (NL-DR etc.) (to be able to visualize it on a map)\n",
    "\n",
    "isos = sorted(list(set(nl_covid_clean['region_code'])))\n",
    "names = sorted(list(set(nl_covid_clean['region_name'])))\n",
    "isos_names = dict(zip(names,isos))\n",
    "\n",
    "reg_dict = {}\n",
    "for i in isos_names.keys():\n",
    "    reg_dict[i] = []\n",
    "\n",
    "for i in isos_names.keys():\n",
    "    mask = (tests['Security_region_name'] == i) \n",
    "    mask2 = (weather_corona['region_name'] == i)\n",
    "    mask_covid=tests[mask]\n",
    "    mask_covid2 = weather_corona[mask2]\n",
    "    reg_dict[i].append(isos_names[i])\n",
    "    reg_dict[i].append(sum(mask_covid['Tested_with_result']))\n",
    "    reg_dict[i].append(sum(mask_covid['Tested_positive']))\n",
    "    reg_dict[i].append(list(set(mask_covid2['population']))[0])\n",
    "    \n",
    "df1 = pd.DataFrame.from_dict(reg_dict).transpose()\n",
    "df1= df1.reset_index()\n",
    "df1.rename(columns = {'index':'region',0:'region code', 1:'Total tests',2:'Tested positive',3:'Population'}, inplace = True)\n",
    "\n",
    "\n",
    "df1['Per test'] = df1['Tested positive']/df1['Total tests']\n",
    "df1['Tests per capita'] = df1['Total tests'] / df1['Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of populaton of people that got tested\n",
    "#Maybe the less infected regions, are not what they seem to be\n",
    "\n",
    "nl_map = folium.Map(location = [52.3,5.5], zoom_start = 7.4)\n",
    "folium.Choropleth(\n",
    "    geo_data = '../Data/Raw/shapefiles/nl.geojson',\n",
    "    name = \"Total tests and positive tests\",\n",
    "    data = df1,\n",
    "    columns = ['region code', 'Tests per capita'],\n",
    "    key_on = \"properties.iso_3166_2\",\n",
    "    fill_color = \"OrRd\",\n",
    "    fill_opacity = 0.7,\n",
    "    line_opacity = 0.2,\n",
    "    legend_name = \"Number of tests per capita\",\n",
    ").add_to(nl_map)\n",
    "\n",
    "nl_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
